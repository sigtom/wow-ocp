# Media Stack Deployment Template
# Production-ready deployment with rclone sidecar pattern
# 
# Usage:
#   1. Copy this template: cp templates/media-deployment.yaml apps/<app-name>/base/deployment.yaml
#   2. Replace placeholders: {{APP_NAME}}, {{IMAGE}}, {{PORT}}, {{ZONE}}
#   3. Customize resources, environment variables as needed
#   4. Commit to Git and sync via ArgoCD
#
# Placeholders:
#   {{APP_NAME}}  - Application name (e.g., prowlarr, bazarr, jellyfin)
#   {{IMAGE}}     - Container image (e.g., lscr.io/linuxserver/prowlarr:latest)
#   {{PORT}}      - Primary service port (e.g., 9696, 6767)
#   {{ZONE}}      - Logical zone (zone1-4, default: zone2)
#   {{CPU_REQ}}   - CPU request (e.g., 500m, 1000m)
#   {{MEM_REQ}}   - Memory request (e.g., 512Mi, 2Gi)
#   {{CPU_LIM}}   - CPU limit (e.g., 2000m, 4000m)
#   {{MEM_LIM}}   - Memory limit (e.g., 2Gi, 8Gi)

apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{APP_NAME}}
  namespace: media-stack
  labels:
    app: {{APP_NAME}}
    zone: {{ZONE}}
    stack: hybrid-media
spec:
  replicas: 1
  strategy:
    type: Recreate  # Avoid multiple pods mounting same PVC path
  selector:
    matchLabels:
      app: {{APP_NAME}}
  template:
    metadata:
      labels:
        app: {{APP_NAME}}
        zone: {{ZONE}}
        stack: hybrid-media
      annotations:
        # Force restart on secret change
        checksum/rclone-zurg-config: "{{ .Values.rcloneZurgConfigChecksum }}"
        checksum/rclone-config: "{{ .Values.rcloneConfigChecksum }}"
    spec:
      serviceAccountName: managers  # Change if different zone (e.g., plex, cloud-gateway)
      
      # Security context for pod
      securityContext:
        fsGroup: 1000  # Ensure files writable by app UID
      
      # Prefer Node 2/3 for superior networking (10G NIC) and CPU
      # This is a SOFT preference - allows fallback to Node 4 if needed
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - wow-ocp-node2
                - wow-ocp-node3
      
      # Create mount points before sidecars start
      # Prevents "directory not found" errors from rclone
      initContainers:
      - name: init-dirs
        image: docker.io/alpine:latest
        command:
          - /bin/sh
          - -c
          - |
            echo "Creating mount point directories..."
            mkdir -p /mnt/media/zurg /mnt/media/torbox
            echo "Verifying directory creation..."
            ls -la /mnt/media/
            echo "Mount points ready"
        volumeMounts:
        - name: media-storage
          mountPath: /mnt/media
        resources:
          requests:
            cpu: 10m
            memory: 16Mi
          limits:
            cpu: 100m
            memory: 64Mi
      
      containers:
      # ============================================================================
      # SIDECAR 1: rclone-zurg (Real-Debrid via Zurg WebDAV)
      # ============================================================================
      - name: rclone-zurg
        image: docker.io/rclone/rclone:latest
        
        # CRITICAL: privileged required for FUSE (/dev/fuse access)
        securityContext:
          privileged: true
        
        # Rclone mount command with optimized caching
        args:
        - "mount"
        - "zurg:"                         # Remote name from rclone.conf
        - "/mnt/media/zurg"               # Mount point (created by init-dirs)
        - "--config=/config/rclone/rclone.conf"
        - "--allow-other"                 # Allow other users (main container)
        - "--vfs-cache-mode=full"         # Cache metadata + data (aggressive)
        - "--poll-interval=10s"           # Check for new files every 10s
        - "--dir-cache-time=10s"          # Cache directory listings for 10s
        - "--attr-timeout=10s"            # Cache file attributes for 10s
        - "--rc"                          # Enable remote control API
        - "--rc-no-auth"                  # No auth (localhost only)
        - "--rc-addr=:5572"               # Remote control port (unique)
        - "--log-level=INFO"              # Logging verbosity
        
        # Volume mounts with BIDIRECTIONAL propagation
        # This allows FUSE mount to be visible in main container
        volumeMounts:
        - name: media-storage
          mountPath: /mnt/media
          mountPropagation: Bidirectional  # CRITICAL: Propagate FUSE mount
        - name: rclone-zurg-config
          mountPath: /config/rclone
          readOnly: true
        
        # Resource limits to prevent CPU saturation
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m      # Cap CPU (rclone can be intensive)
            memory: 1Gi    # VFS cache memory
        
        # Liveness probe: Check if mount is healthy
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "test -d /mnt/media/zurg/__all__ || exit 1"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        # Startup probe: Wait for initial mount
        startupProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "test -d /mnt/media/zurg/__all__ || exit 1"
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 12  # 60s total timeout
      
      # ============================================================================
      # SIDECAR 2: rclone-torbox (TorBox WebDAV)
      # ============================================================================
      - name: rclone-torbox
        image: docker.io/rclone/rclone:latest
        
        # CRITICAL: privileged required for FUSE (/dev/fuse access)
        securityContext:
          privileged: true
        
        # Rclone mount command (similar to zurg but different remote)
        args:
        - "mount"
        - "torbox:"                       # Remote name from rclone.conf
        - "/mnt/media/torbox"             # Mount point (different from zurg)
        - "--config=/config/rclone/rclone.conf"
        - "--allow-other"
        - "--vfs-cache-mode=full"
        - "--poll-interval=10s"
        - "--dir-cache-time=10s"
        - "--attr-timeout=10s"
        - "--rc"
        - "--rc-no-auth"
        - "--rc-addr=:5573"               # Different port than zurg (5573)
        - "--log-level=INFO"
        
        # Volume mounts with BIDIRECTIONAL propagation
        volumeMounts:
        - name: media-storage
          mountPath: /mnt/media
          mountPropagation: Bidirectional  # CRITICAL: Propagate FUSE mount
        - name: rclone-config
          mountPath: /config/rclone
          readOnly: true
        
        # Resource limits
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
        
        # Liveness probe: Check if mount is healthy
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "test -d /mnt/media/torbox/torrents || exit 1"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        # Startup probe: Wait for initial mount
        startupProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "test -d /mnt/media/torbox/torrents || exit 1"
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 12
      
      # ============================================================================
      # MAIN CONTAINER: Application
      # ============================================================================
      - name: {{APP_NAME}}
        image: {{IMAGE}}
        
        # Standard LinuxServer.io environment variables
        # Adjust for other container images as needed
        env:
        - name: PUID
          value: "1000"
        - name: PGID
          value: "1000"
        - name: TZ
          value: "America/New_York"
        - name: UMASK
          value: "022"
        
        # Application port
        ports:
        - containerPort: {{PORT}}
          name: http
          protocol: TCP
        
        # Volume mounts with HOSTOCONTAINER propagation
        # This allows main container to RECEIVE mounts from sidecars
        volumeMounts:
        # Config directory (persistent app state)
        - name: media-storage
          mountPath: /config
          subPath: config/{{APP_NAME}}
        
        # Rclone config directory (for apps that need direct rclone access)
        - name: media-storage
          mountPath: /config/rclone
          subPath: config/rclone
        
        # Media directory (cloud mounts + local storage)
        # CRITICAL: HostToContainer propagation receives FUSE mounts from sidecars
        - name: media-storage
          mountPath: /mnt/media
          mountPropagation: HostToContainer  # CRITICAL: Receive mounts (one-way)
        
        # Health probes
        livenessProbe:
          tcpSocket:
            port: {{PORT}}
          initialDelaySeconds: 40
          periodSeconds: 20
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          tcpSocket:
            port: {{PORT}}
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        # Resource requests/limits for main application
        # Adjust based on app requirements (transcoding, indexing, etc.)
        resources:
          requests:
            cpu: {{CPU_REQ}}
            memory: {{MEM_REQ}}
          limits:
            cpu: {{CPU_LIM}}
            memory: {{MEM_LIM}}
      
      # ============================================================================
      # VOLUMES
      # ============================================================================
      volumes:
      # PVC for TrueNAS NFS storage (RWX - shared across pods)
      - name: media-storage
        persistentVolumeClaim:
          claimName: media-library-pvc
      
      # Secret for Zurg/Real-Debrid credentials
      - name: rclone-zurg-config
        secret:
          secretName: rclone-zurg-config
          defaultMode: 0400  # Read-only for owner
      
      # Secret for TorBox credentials
      - name: rclone-config
        secret:
          secretName: rclone-config
          defaultMode: 0400  # Read-only for owner
---
# ============================================================================
# SERVICE (ClusterIP for internal access)
# ============================================================================
apiVersion: v1
kind: Service
metadata:
  name: {{APP_NAME}}
  namespace: media-stack
  labels:
    app: {{APP_NAME}}
    zone: {{ZONE}}
spec:
  type: ClusterIP  # Change to LoadBalancer if external access needed
  selector:
    app: {{APP_NAME}}
  ports:
  - protocol: TCP
    port: {{PORT}}
    targetPort: {{PORT}}
    name: http
  sessionAffinity: None  # Change to ClientIP if sticky sessions needed
---
# ============================================================================
# ROUTE (OpenShift external access)
# ============================================================================
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: {{APP_NAME}}
  namespace: media-stack
  labels:
    app: {{APP_NAME}}
    zone: {{ZONE}}
  annotations:
    # TLS edge termination (OpenShift router handles TLS)
    # Change to passthrough if app handles TLS internally
    haproxy.router.openshift.io/timeout: 5m
spec:
  host: {{APP_NAME}}.apps.ossus.sigtomtech.com
  to:
    kind: Service
    name: {{APP_NAME}}
    weight: 100
  port:
    targetPort: http
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
---
# ============================================================================
# SERVICE ACCOUNT (Optional - if not using default)
# ============================================================================
# apiVersion: v1
# kind: ServiceAccount
# metadata:
#   name: {{APP_NAME}}
#   namespace: media-stack
# ---
# # SCC Binding (grant privileged for FUSE sidecars)
# # Run: oc adm policy add-scc-to-user privileged -z {{APP_NAME}} -n media-stack
